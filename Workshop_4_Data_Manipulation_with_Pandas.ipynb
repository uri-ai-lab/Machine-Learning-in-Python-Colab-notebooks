{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uri-ai-lab/Machine-Learning-in-Python-Colab-notebooks/blob/main/Workshop_4_Data_Manipulation_with_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-2nECFhXXqq"
      },
      "source": [
        "# Data Manipulation with Pandas\n",
        "\n",
        "Pandas supports 1-D (Series), 2-D (DataFrame), and 3-D (Panel) data structures.  Here we cover DataFrames because they most closely resemble the kind of data tables data scientists mostly look at.\n",
        "\n",
        "The advantage of Pandas is that it stores the data together with its *metadata*.\n",
        "\n",
        "The most often used meta data with Pandas are the **column names** and the **index**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhcrljqhXXqq"
      },
      "source": [
        "import pandas\n",
        "import numpy # for random number generation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CFP_ohSXXqr"
      },
      "source": [
        "df = pandas.read_csv(\"https://raw.githubusercontent.com/IndraniMandal/CSC310-S20/master/notes/assets/mammals.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhkYr4qQ9YQd"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDznYh2N9YQl"
      },
      "source": [
        "# DataFrame Parts\n",
        "\n",
        "A dataframe is composed of different parts that work together to give a coherent view of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEUjZRUe9YQm"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGGQ432K9YQr"
      },
      "source": [
        "df.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByLCToRM9YQw"
      },
      "source": [
        "df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC5Exzbd9YQ2"
      },
      "source": [
        "We can change the parts of the data.  For example, we can create a new index for our dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIHxtlye9YQ3"
      },
      "source": [
        "df.index = ['Dog', 'Duck', 'Frog', 'Bat', 'Bar Stool']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to rename a specific Columns"
      ],
      "metadata": {
        "id": "fc5vRHr_if6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns = {'Mammal' : 'Mammals'}, inplace=True)"
      ],
      "metadata": {
        "id": "WPNHOXpOifOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HstQJi7o9YQ8"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bmbLLsV9YRA"
      },
      "source": [
        "# Indexing and Slicing\n",
        "\n",
        "For array-style indexing Pandas  uses the **loc**, **iloc**, and **ix** indexers.\n",
        "\n",
        "Using the **iloc** indexer, we can index the underlying array as if it is a simple array using row and column integer values (hence the i in iloc). The DataFrame index and column labels are maintained in the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4bD9BiJ9YRB"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c23dws3G9YRE"
      },
      "source": [
        "df.iloc[:2,1:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwDf5Gtj9YRI"
      },
      "source": [
        "Using the **loc** indexer we can index the underlying data in an array-like style but using the explicit index and column names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI3Ixcyp9YRJ"
      },
      "source": [
        "df.loc[:'Duck','Wings':'Feathers']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUKXyHgR9YRM"
      },
      "source": [
        "Notice that when slicing with an explicit index (i.e., data.loc['a':'c']), the final index is included in the slice, while when slicing with an implicit index (i.e., data.iloc[0:2]), the final index is excluded from the slice.\n",
        "\n",
        "The indexer **ix** allows the mix of integer and explicit indexing. (This indexer is deprecated from pandas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5su4Zyv9YRN"
      },
      "source": [
        "# Data Access Patterns\n",
        "\n",
        "We can use relational and boolean expressions when selecting data from a dataframe.\n",
        "\n",
        "In order to see that we have to realize that there is another simple way to select frame columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXYZ6nJn9YRO"
      },
      "source": [
        "df[['Wings', 'Mammal']] # using a list of column names to access columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hineelv89YRR"
      },
      "source": [
        "Relational Operators:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvNPy0bB9YRR"
      },
      "source": [
        "df[df.Wings == 'yes'] # accessing rows for which the equality holds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uif08wAl9YRU"
      },
      "source": [
        "df[df.Wings == 'yes'].Mammal # accessing attribute values for rows for which the equality holds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ritWwu39YRX"
      },
      "source": [
        "df[(df.Wings == 'yes') & (df.Fur == 'yes')] # boolean operations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LPTd-Gn9YRa"
      },
      "source": [
        "# Filtering\n",
        "\n",
        "Boolean indexing using a Boolean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSRn0Ue_9YRb"
      },
      "source": [
        "df.Mammal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7RaC5dA9YRe"
      },
      "source": [
        "df.Mammal.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2--h2IK-9YRg"
      },
      "source": [
        "df[df.Mammal == False] # or we could have just said df[df.Mammal]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpEmWWLeiBET"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PT8KdCX9YRj"
      },
      "source": [
        "Filtering using **isin()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVbSzj5L9YRj"
      },
      "source": [
        "df.index.isin(['Dog','Bat'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3CsysYD9YRl"
      },
      "source": [
        "Any Boolean vector can be used as filter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR6HQdN69YRm"
      },
      "source": [
        "v = df.index.isin(['Dog','Bat'])\n",
        "df[v]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw9NNCZ_9YRo"
      },
      "source": [
        "# Combining DataFrames\n",
        "\n",
        "## Using concat() along axis 1 (columns)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toy8E4q99YRo"
      },
      "source": [
        "df1 = df.iloc[:,:2]\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvEmapd9YRr"
      },
      "source": [
        "df2 = df.iloc[:,2:]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFPAHGh99YRx"
      },
      "source": [
        "pandas.concat([df1,df2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQJSX2RL9YR0"
      },
      "source": [
        "**Note** The two dataframes have to agree on the index!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quwp41LE9YR1"
      },
      "source": [
        "Creating a new index on df2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j1vjxSr9YR1"
      },
      "source": [
        "df2.reset_index(drop=True, inplace=True)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62eK9wmvEV6E"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6jaF75D9YR3"
      },
      "source": [
        "pandas.concat([df1,df2],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN0j3jds9YR5"
      },
      "source": [
        "### Using concat() along axis 0 (rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpKDbHzw9YR6"
      },
      "source": [
        "piece1 = df.iloc[:2,:]\n",
        "piece1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBQtHzGiFV1q"
      },
      "source": [
        "piece2 = df.iloc[2:,:]\n",
        "piece2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHWWprJi9YR9"
      },
      "source": [
        "pandas.concat([piece1, piece2],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEO-blO4Huh1"
      },
      "source": [
        "piece1.append(piece2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwCRdC3n9YSD"
      },
      "source": [
        "**Note** dataframes have to agree on column names!\n",
        "\n",
        "**append** function work very similarly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnh-CJNs9YSE"
      },
      "source": [
        "# Missing or Duplicated Data\n",
        "* Pandas flags missing values with NaN (not a number).\n",
        "* In most cases, any computations applied to a dataframe with NaNs will ignore the NaNs\n",
        "* However, it is still a good idea to clean up the dataframe\n",
        "* In general we have two options to deal with missing data:\n",
        " * Either drop the row or columns that has NaNs\n",
        " * Or try to substitute a reasonable value for the NaN\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ashWfVe9YSF"
      },
      "source": [
        "Generate a dataset with NaNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxCh-rkb9YSG"
      },
      "source": [
        "df = pandas.DataFrame(numpy.random.randn(4, 3), index=['a', 'c', 'd', 'e'],\n",
        "                  columns=['one', 'two', 'three'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQXiLgpg9YSL"
      },
      "source": [
        "Generating NaNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHqoCEwc9YSM"
      },
      "source": [
        "df2 = df.reindex(['a', 'b', 'c', 'd', 'e','f'])\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X3yXEI19YSR"
      },
      "source": [
        "# find the places where the NaNs are\n",
        "df2.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1QGb5EfKa25"
      },
      "source": [
        "df2.one[df2.one.isnull()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luRj8uge9YSW"
      },
      "source": [
        "# look at the values of the isnull dataframe\n",
        "df2.isnull().values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoUxS1f29YSa"
      },
      "source": [
        "# find out how many values are missing\n",
        "# NOTE: sum treats 'True' as 1 and 'False' as 0\n",
        "df2.isnull().values.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7uzPorO9YSd"
      },
      "source": [
        "# drop rows that have NaNs\n",
        "df2.dropna(how='any',axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFw0geAH9YSg"
      },
      "source": [
        "# dropping columns that have NaNs\n",
        "# NOTE: this is NOT always a good idea -- empty dataframe!\n",
        "df2.dropna(how='any',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-2_uV-F9YSj"
      },
      "source": [
        "# Replacing Missing Data\n",
        "\n",
        "We can also try to estimate the missing data - **impute** it.\n",
        "\n",
        "We replace the missing values by the means of each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-BoZp7U9YSk"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOvo1zoB9YSn"
      },
      "source": [
        "# compute the mean of each column\n",
        "df2.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8RSfCCX9YSq"
      },
      "source": [
        "# fill the missing values in each column\n",
        "for c in df.columns:\n",
        "    df2[c].fillna(df[c].mean(), inplace=True)\n",
        "\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF1_6FeK9YSt"
      },
      "source": [
        "# Broadcasting\n",
        "\n",
        "Binary arithmetic operators are applied element by element to dataframes assuming equal sized dataframes.\n",
        "\n",
        "Broadcasting refers to the fact that Python will reuse elements of the smaller dataframe or will reuse a scalar in order to complete the binary operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rk8mleg9YSu"
      },
      "source": [
        "df = pandas.DataFrame([[1,2],[3,4]])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOJtM1NE9YSy"
      },
      "source": [
        "# element by element operation\n",
        "df + df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI9UZd7U9YS1"
      },
      "source": [
        "# broadcasting the smaller vector\n",
        "# NOTE: each element of the vector is applied to\n",
        "#       a column in the dataframe\n",
        "df + [10, 20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49bE9wcM9YS5"
      },
      "source": [
        "# broadcasting a scalar\n",
        "# NOTE: the scalar is applied to ALL elements\n",
        "#       of the dataframe\n",
        "df + 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ehNieq59YS9"
      },
      "source": [
        "# we can now say things like this\n",
        "df + df == 2*df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx2ZAUcH9YTB"
      },
      "source": [
        "# Duplicate Data\n",
        "\n",
        "Identify and remove duplicate rows in a DataFrame\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuUSIUQ09YTB"
      },
      "source": [
        "# make a dataframe with duplicate rows 'b' and 'e'\n",
        "df2.iloc[4,:] = df2.iloc[1,:]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-TDgA8M9YTE"
      },
      "source": [
        "# check if there is duplication\n",
        "df2.duplicated()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfQ6OIbWMPkZ"
      },
      "source": [
        "df2[df2.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngd0omUS9YTI"
      },
      "source": [
        "# drop e!\n",
        "df2.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk7FeryK9YTN"
      },
      "source": [
        "By default **duplicated()** and **drop_duplicates()** keep the first and identify other reoccuring instances as duplicates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pumStGr9YTN"
      },
      "source": [
        "# Reading\n",
        "\n",
        "* 2 [The Basics of NumPy Arrays](https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html)\n",
        "* 3.2 [Data Indexing and Selection](https://jakevdp.github.io/PythonDataScienceHandbook/03.02-data-indexing-and-selection.html)\n",
        "* 3.3 [Operating on Data in Pandas](https://jakevdp.github.io/PythonDataScienceHandbook/03.03-operations-in-pandas.html)\n",
        "* 3.4 [Handling Missing Data](https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html)\n",
        "* 3.6 [Combining Datasets: Concat and Append](https://jakevdp.github.io/PythonDataScienceHandbook/03.06-concat-and-append.html)\n",
        "* 3.7 [Combining Datasets: Merge and Join](https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html)\n",
        "* 3.8 [Aggregation and Grouping](https://jakevdp.github.io/PythonDataScienceHandbook/03.08-aggregation-and-grouping.html)"
      ]
    }
  ]
}